---
title: "Chapter 6 - Exploring detections data"
---

> In this chapter, we'll finally start exploring our data by summarizing, plotting and mapping.

```{r setup, include = FALSE}
# Get and update sample data to avoid messages later
sql_motus <- motus:::get_sample_data()

# Re-download lakes if necessary
if(!dir.exists("map-data")) dir.create("map-data")
sql_motus <- motus:::get_sample_data()
if(!file.exists("map-data/ne_50m_lakes.shp")) {
  rnaturalearth::ne_download(scale = "medium", type = 'lakes', category = 'physical',
                            returnclass = "sf", destdir = "map-data")
}
```

Once you have clarified any possible ambiguous tags and removed false positives, you are ready to start analyzing your clean data set. 
This chapter will walk you through some simple procedures to start working with and visualizing the clean sample data set;
you can modify these scripts to work with your own data. 
For a more in-depth R tutorial we strongly recommend working through [R for Data Science](https://r4ds.hadley.nz/) by Garrett Grolemund and Hadley Wickham.

## Load required packages

Follow the instructions in [Chapter 2](02-installing-packages.html) to install the following packages before loading, if you haven't already done so.

```{r message = FALSE, warning = FALSE}
library(motus)
library(tidyverse)
library(sf)
library(lubridate)
library(rnaturalearth)

Sys.setenv(TZ = "UTC")
```


## Load data

If you followed along with the the previous Chapter ([Chapter 5 - Data cleaning](05-data-cleaning.html)) and are working with the cleaned `df_alltags_sub` file, you can skip this step and go directly to [Summarizing your data](#summarizing-your-data).  

Otherwise, if you saved your data as an RDS file, you can load it using:

```{r, eval = FALSE}
df_alltags_sub <- readRDS("./data/dfAlltagsSub.rds") # change dir to local directory
```

Or, if you've applied a custom filter to your `.motus` file, you can load the previously downloaded sample Motus data (see [Chapter 3](03-accessing-data.html)) and clean it now. 
Currently the main benefit of using the custom filter is that you apply the filter to the `.motus` file, which allows you more flexibility in applying `dplyr` functions to manage and filter the data
(e.g., you can select different variables to include in the data than we included in the RDS file in [Chapter 5 - Data cleaning](05-data-cleaning.html)). 
This approach also allows you to more readily integrate new data added to your database with the `tagme()` function. 
Because we are selecting the same variables and filtering the same records, the following gives you the same dataset as the `readRDS()` statement above:

```{r}
# load the .motus file (remember 'motus.sample' is both username and password)
sql_motus <- tagme(176, dir = "./data/")
tbl_alltags <- tbl(sql_motus, "alltags")

# obtain a table object of the filter
tbl_filter <- getRunsFilters(sql_motus, "filtAmbigFalsePos")

# filter and convert the table into a dataframe, with a few modications
df_alltags_sub <- left_join(tbl_alltags, tbl_filter, by = c("runID", "motusTagID")) %>%
  mutate(probability = ifelse(is.na(probability), 1, probability)) %>%
  filter(probability > 0) %>%
  collect()

# Now Let's clarify the dates and names for use in the following examples
df_alltags_sub <- df_alltags_sub %>%
  mutate(time = as_datetime(ts),  # work with times AFTER transforming to flat file
         tagDeployStart = as_datetime(tagDeployStart),
         tagDeployEnd = as_datetime(tagDeployEnd),
         recvDeployName = if_else(is.na(recvDeployName), 
                                  paste(recvDeployLat, recvDeployLon, sep=":"), 
                                  recvDeployName))

```

**Note that if your project is very large, you may want to convert only a portion of it to the dataframe, to avoid memory issues.** 

Details on filtering the `tbl` prior to collecting as a dataframe are available in [Converting to flat data in Chapter 3](03-accessing-data.html#converting-to-flat-data).  

Here we do so by adding a filter to the above command, in this case, only creating a dataframe for `motusTagID` 16047, but you can decide how to best subset your data based on your need (e.g. by species or year):

```{r}
# create a subset for a single tag, to keep the dataframe small
df_alltags_16047 <- filter(df_alltags_sub, motusTagID == 16047) 
```

## Summarizing your data

Here we will run through some basic commands, starting with the `summary()` function to view a selection of variables in a data frame:

```{r}
sql_motus %>% 
  tbl("alltags") %>% 
  select(ts, motusTagID, runLen, speciesEN, tagDepLat, tagDepLon, 
         recvDeployLat, recvDeployLon) %>% 
  collect() %>%
  mutate(time = as_datetime(ts)) %>% 
  summary()

# same summary for the filtered sql data
df_alltags_sub %>% 
  select(time, motusTagID, runLen, speciesEN, tagDepLat, tagDepLon, 
         recvDeployLat, recvDeployLon) %>% 
  summary()
```

The `dplyr` package allows you to easily summarize data by group, manipulate variables, or create new variables based on your data.  

We can manipulate existing variables or create new ones with `dplyr`'s `mutate()` function, here we'll convert `ts` to a date/time format, then make a new variable for year and day of year (`doy`).

We'll also remove the set of points with missing receiver latitude and longitudes. 
These may be useful in some contexts (for example if the approximate location of the receiver is known) but can cause warnings or errors when plotting. 

```{r}
df_alltags_sub <- df_alltags_sub %>%
  mutate(year = year(time), # extract year from time
         doy = yday(time)) %>% # extract numeric day of year from time
  filter(!is.na(recvDeployLat))

head(df_alltags_sub)
```

We can also summarize information by group, in this case `motusTagID`, and apply various functions to these groups such as getting the total number of detections (`n`) for each tag, the number of receivers each tag was detected on, the first and last detection date, and the total number of days there was at least one detection:

```{r}
tagSummary <- df_alltags_sub %>%
  group_by(motusTagID) %>% 
  summarize(nDet = n(),
            nRecv = length(unique(recvDeployName)),
            timeMin = min(time),
            timeMax = max(time),
            totDay = length(unique(doy)))

head(tagSummary)
```

We can also group by multiple variables; 
applying the same function as above but now grouping by `motusTagID` and `recvDeployName`, we will get information for each tag detected on each receiver. 
Since we are grouping by `recvDeployName`, there will be by default only one `recvDeployName` in each group, thus the variable `nRecv` will be 1 for each row. 
This in not very informative, however we include this to help illustrate how grouping works:

```{r}
tagRecvSummary <- df_alltags_sub %>%
  group_by(motusTagID, recvDeployName) %>% 
  summarize(nDet = n(),
            nRecv = length(unique(recvDeployName)),
            timeMin = min(time),
            timeMax = max(time),
            totDay = length(unique(doy)), .groups = "drop")

head(tagRecvSummary)
```

## Plotting your data

Plotting your data is a powerful way to visualize broad and fine-scale detection patterns.
This section will give you a brief introduction to plotting using `ggplot2`.
For more in depth information on the uses of `ggplot2`, we recommend the [Cookbook for R](http://www.cookbook-r.com/Graphs/), and the RStudio [`ggplot2` cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf).  

To make coarse-scale plots with large files, we suggest first rounding the detection time to the nearest hour or day so that processing time is faster.
Here we round detection times to the nearest hour, then make a basic plot of hourly detections by `motusTagID`:

```{r}
df_alltags_sub_2 <- df_alltags_sub %>%
  mutate(hour = hour(time)) %>% 
  select(motusTagID, port, tagDeployStart, tagDepLat, tagDepLon, 
         recvDeployLat, recvDeployLon, recvDeployName, antBearing, speciesEN, year, doy, hour) %>% 
  distinct()

ggplot(data = df_alltags_sub_2, aes(x = hour, y = as.factor(motusTagID))) +
  theme_bw() +
  geom_point() + 
  labs(x = "Hour", y = "MotusTagID")
```

Let's focus only on tags deployed in 2016, and we can colour the tags by species:

```{r}
ggplot(data = filter(df_alltags_sub_2, year(tagDeployStart) == 2016), 
       aes(x = hour, y = as.factor(motusTagID), colour = speciesEN)) +
  theme_bw() + 
  geom_point() +
  labs(x = "Hour", y = "MotusTagID") +
  scale_colour_discrete(name = "Species")
```

We can see how tags moved latitudinally by first ordering by hour, and colouring by `motusTagID`:

```{r warnings = FALSE}
df_alltags_sub_2 <- arrange(df_alltags_sub_2, hour)

ggplot(data = filter(df_alltags_sub_2, year(tagDeployStart) == 2016), 
       aes(x = hour, y = recvDeployLat, col = as.factor(motusTagID), 
           group = as.factor(motusTagID))) + 
  theme_bw() + 
  geom_point() +
  geom_path() +
  labs(x = "Hour", y = "Receiver latitude") +
  scale_colour_discrete(name = "MotusTagID")
```

Now let's look at more detailed plots of signal variation. 
We use the full `df_alltags_sub` dataframe so that we can get signal strength for each detection of a specific tag.
Let's examine fall 2016 detections of tag 22897 at Niapiskau; we facet the plot by deployment name, ordered by decreasing latitude:

```{r}
ggplot(data = filter(df_alltags_sub, 
                     motusTagID == 22897, 
                     recvDeployName == "Niapiskau"), 
       aes(x = time, y = sig)) +
  theme_bw() + 
  geom_point() + 
  labs(x = "Time", y = "Signal strength") +
  facet_grid(recvDeployName ~ .)
```

We use the `sunRiseSet()` to get sunrise and sunset times for all detections. 
We then zoom in on a certain timeframe and add that information to the above plot by adding a `geom_vline()` statement to the code, which adds a yellow line for sunrise time, and a blue line for sunset time:

```{r}
# add sunrise and sunset times to the dataframe
df_alltags_sub <- sunRiseSet(df_alltags_sub, lat = "recvDeployLat", lon = "recvDeployLon") 

ggplot(data = filter(df_alltags_sub, motusTagID == 22897,
                     time > "2016-10-11",
                     time < "2016-10-17",
                     recvDeployName == "Niapiskau"), 
       aes(x = time, y = sig)) +
  theme_bw() + 
  geom_point() + 
  labs(x = "Time of year", y = "Signal strength") +
  geom_vline(aes(xintercept = sunrise), col = "orange") + 
  geom_vline(aes(xintercept = sunset), col = "blue")
```

We can see that during this period, the tag was most often detected during the day, suggesting it may be actively foraging in this area during this time.  

The same plots can provide valuable movement information when the receivers are ordered geographically. We do this for `motusTagID` 16039:

```{r}
# We'll first order sitelat by latitude (for plots)
df_alltags_sub <- mutate(df_alltags_sub, 
                         recvDeployName = reorder(recvDeployName, recvDeployLat))

ggplot(data = filter(df_alltags_sub, 
                     motusTagID == 16039,
                     time < "2015-10-01"), 
       aes(x = time, y = recvDeployName)) +
  theme_bw() + 
  geom_point() + 
  labs(x = "Time of year", y = "Receiver name (ordered by latitude)")
```

We zoom in on a section of this plot and look at antenna bearings to see directional movement past stations:

```{r}
ggplot(data = filter(df_alltags_sub, motusTagID == 16039, 
                     time > "2015-09-14", 
                     time < "2015-10-01"), 
       aes(x = time, y = sig, col = as.factor(antBearing))) +
  theme_bw() + 
  geom_point() + 
  labs(x = "Time of day", y = "Signal strength") +
  scale_color_discrete(name = "Antenna bearing") +
  facet_grid(recvDeployName ~ .)
```

This plot shows the typical fly-by pattern of a migrating animal, with signal strength increasing and then decreasing as the tag moves through the beams of the antennas.

## Mapping your data

To generate maps of tag paths, we will once again use summarized data so we can work with a much smaller database for faster processing.
Here we'll summarize detections by day.
We will use code similar to the code we used in [Chapter 5 - Data cleaning](05-data-cleaning.html), however, here we will create a simple function to summarize the data, since we will likely want to do this type of summary over and over again. 

```{r}
# Simplify the data by summarizing by the runID
# If you want to summarize at a finer (or coarser) scale, you can also create
# other groups.

fun.getpath <- function(df) {
  df %>%
    filter(tagProjID == 176, # keep only tags registered to the sample project
           !is.na(recvDeployLat) | !(recvDeployLat == 0)) %>% 
    group_by(motusTagID, runID, recvDeployName, ambigID, 
             tagDepLon, tagDepLat, recvDeployLat, recvDeployLon) %>%
    summarize(max.runLen = max(runLen), time = mean(time), .groups = "drop") %>%
    arrange(motusTagID, time) %>%
    data.frame()
} # end of function call

df_alltags_path <- fun.getpath(df_alltags_sub)
```

```{r}
df_alltags_sub_path <- df_alltags_sub %>%
  filter(tagProjID == 176) %>% # only tags registered to project
  arrange(motusTagID, time) %>%       # order by time stamp for each tag
  mutate(date = as_date(time)) %>%    # create date variable
  group_by(motusTagID, date, recvDeployName, ambigID, 
           tagDepLon, tagDepLat, recvDeployLat, recvDeployLon)

df_alltags_path <- fun.getpath(df_alltags_sub_path)
```

### Creating simple maps with the `sf` package

Mapping allows us to spatially view our data and connect sequential detections that may represent flight paths in some cases. First we load base maps from the `rnaturalearth` package. Please see [Chapter 4](04-deployments.html#location-of-tag-deployments) for more detail if you have not already downloaded the `rnaturalearth` shapefiles.

```{r}
world <- ne_countries(scale = "medium", returnclass = "sf") 
lakes <- ne_load(type = "lakes", scale = "medium", category = 'physical',
                 returnclass = "sf",
                 destdir = "map-data") # use this if already downloaded shapefiles
```

Then, to map the paths, we set the x-axis and y-axis limits based on the location of receivers with detections. 
Depending on your data, these might need to be modified to encompass the deployment location of the tags, if tags were not deployed near towers with detections. 
We then use `ggplot` and `sf` to plot the map and tag paths. 
We add points for receivers and lines connecting consecutive detections by `motusTagID`. We also include an 'x' for where tags were deployed.

```{r}
# just use the tags that we have examined carefully and filtered (in the
# previous chapter)
df_tmp <- df_alltags_path %>%
  filter(motusTagID %in% c(16011, 16035, 16036, 16037, 16038, 16039)) %>%
  arrange(time)  %>% # arrange by hour
  as.data.frame()

# set limits to map based on locations of detections, ensuring they include the
# deployment locations
xmin <- min(df_tmp$recvDeployLon, na.rm = TRUE) - 2
xmax <- max(df_tmp$recvDeployLon, na.rm = TRUE) + 2
ymin <- min(df_tmp$recvDeployLat, na.rm = TRUE) - 1
ymax <- max(df_tmp$recvDeployLat, na.rm = TRUE) + 1

# map
ggplot(data = world) + 
  geom_sf(colour = NA) +
  geom_sf(data = lakes, colour = NA, fill = "white") +
  coord_sf(xlim = c(xmin, xmax), ylim = c(ymin, ymax), expand = FALSE) +
  theme_bw() + 
  labs(x = "", y = "") +
  geom_path(data = df_tmp, 
            aes(x = recvDeployLon, y = recvDeployLat, 
                group = as.factor(motusTagID), colour = as.factor(motusTagID))) +
  geom_point(data = df_tmp, aes(x = recvDeployLon, y = recvDeployLat), 
             shape = 16, colour = "black") +
  geom_point(data = df_tmp, 
             aes(x = tagDepLon, y = tagDepLat), colour = "red", shape = 4) +
  scale_colour_discrete("motusTagID") 
```
We can also add points for all receivers that were active, but did not detect these birds during a certain time period if we have already downloaded all metadata.

```{r warning = FALSE, message = FALSE, fig.width=10, fig.height=10}
# get receiver metadata
tbl_recvDeps <- tbl(sql_motus, "recvDeps")
df_recvDeps <- tbl_recvDeps %>% 
  collect() %>% 
  mutate(timeStart = as_datetime(tsStart),
         timeEnd = as_datetime(tsEnd),
         # for deployments with no end dates, make an end date a year from now
         timeEnd = if_else(is.na(timeEnd), Sys.time() + years(1), timeEnd))

# get running intervals for all receiver deployments
siteOp <- with(df_recvDeps, interval(timeStart, timeEnd))

# set the date range you're interested in
dateRange <- interval(as_date("2015-08-01"), as_date("2016-01-01"))

# create new variable "active" which will be set to TRUE if the receiver was
# active at some point during your specified date range, and FALSE if not
df_recvDeps$active <- int_overlaps(siteOp, dateRange) 

# create map with receivers active during specified date range as red, and
# receivers with detections as yellow
ggplot(data = world) + 
  geom_sf(colour = NA) +
  geom_sf(data = lakes, colour = NA, fill = "white") +
  coord_sf(xlim = c(xmin, xmax), ylim = c(ymin, ymax), expand = FALSE) +
  theme_bw() + 
  labs(x = "", y = "") +
  geom_point(data = filter(df_recvDeps, active == TRUE), 
             aes(x = longitude, y = latitude), 
             shape = 16, colour = "grey60") +
  geom_path(data = df_tmp, 
            aes(x = recvDeployLon, y = recvDeployLat, 
                group = as.factor(motusTagID), colour = as.factor(motusTagID))) +
  geom_point(data = df_tmp, aes(x = recvDeployLon, y = recvDeployLat), 
             shape = 16, colour = "black") +
  geom_point(data = df_tmp, 
             aes(x = tagDepLon, y = tagDepLat), colour = "red", shape = 4) +
  scale_colour_discrete("motusTagID") 
```

### Mapping with the `ggspatial` package

Mapping with `ggspatial` allows you to select from multiple base layers.  

The first step is to convert the data to spatial data sets.
Then we can plot this data using ggplot2 and the `geom_sf()` function as above. 
We add the base map with the ggspatial function, `annotation_map_tile()`. 
You can change the basemap tiles by using `type = "stamenwatercolor`, ( or "osm", "stamenbw", among others).

We then add points for receivers and lines connecting consecutive detections by `motusTagID.`

Remember that base maps generally require attribution in publications.

```{r message = FALSE}
library(ggspatial)

# just use the tags that we have examined carefully and filtered (in the
# previous chapter)
df_tmp <- df_alltags_path %>%
  filter(motusTagID %in% c(16011, 16035, 16036, 16037, 16038, 16039)) %>%
  arrange(time)  %>% # arrange by hour
  as.data.frame()

# Convert to spatial
df_paths <- points2Path(df_tmp, by = "motusTagID")
df_points <- st_as_sf(df_tmp, coords = c("recvDeployLon", "recvDeployLat"),
                      crs = 4326)

# Plot 
ggplot() +
  theme_bw() +
  annotation_map_tile() +
  geom_sf(data = df_paths, aes(colour = as.factor(motusTagID)), linewidth = 1) +
  geom_sf(data = df_points, shape = 21, colour = "black", fill = "yellow", size = 2) +
  scale_color_viridis_d(name = "MotusTagID", end = 0.8) +
  labs(caption = "Map data from OpenStreetMap")
```

See also the `plotRouteMap()` for a shortcut
function which will produce a similar plot of your entire data base (optionally
limited by date).


### Mapping with the `ggmap` package

> We no longer recommend using the `ggmap` package unless you want to use
> Google Maps and have your own API key.

Mapping with `ggmap` allows you to select from multiple base layers.  
There are several ways to use the `ggmap` package. 
One is with Google Maps, which, as of October 16, 2018, requires a Google Maps API key (see [Troubleshooting](troubleshooting.html#google-maps) for more details).

See the `ggmap` [README](https://github.com/dkahle/ggmap#google-maps) for more details.


The functions above provide examples of how you can begin exploring your data and are by no means exhaustive. 


> **What Next?** [Explore all articles](index.html)

