% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sqliteToRDS.R
\name{sqliteToRDS}
\alias{sqliteToRDS}
\title{Export results of an sqlite query to an .rds file using limited
memory (Linux, OS X; not Windows)}
\usage{
sqliteToRDS(
  con,
  query,
  bind.data = data.frame(),
  out,
  classes = NULL,
  rowsPerBlock = 10000,
  stringsAsFactors = TRUE,
  factorQueries = NULL
)
}
\arguments{
\item{con}{connection to sqlite database}

\item{query}{character scalar; query on con; the entire results of the query
will be written to the .rds file, but the query can include 'limit' and
'offset' phrases.}

\item{bind.data}{values for query parameters, if any; see
\code{\link[DBI:dbGetQuery]{DBI::dbGetQuery()}}.  Defaults to \code{data.frame(x=0L)}, i.e. a trivial
data.frame meant only to pass the sanity checks imposed by
\code{dbGetQuery()}}

\item{out}{character scalar; name of file to which the query results will be
saved.  Should end in ".rds".}

\item{classes}{named list of character vectors; classes for a subset of the
columns in parameter \code{query}}

\item{rowsPerBlock}{maximum number of rows fetched from the DB at a time;
this limits the maximum memory consumed by this function. Default: 10000}

\item{stringsAsFactors}{should string columns be exported as factors?  With
the default value of TRUE, size on disk and size in memory of the
data.frame upon subsequent read will both be smaller, but at the cost of
having to run a separate query on each string column to determine the
levels.  These separate queries might be just as expensive as the full
query, in which case you should specify simpler queries for obtaining
factor levels using \code{factorQueries}.  You can specify FALSE here and still
request that specific text columns be exported as factors by including
\code{'factor'} in the appropriate slot of the \code{classes} parameter.}

\item{factorQueries}{a named character vector of queries for quickly
obtaining the levels for those columns you wish to be factors.  This list
will be consulted for any string column, if \code{stringsAsFactors} is TRUE, and
for any column whose entry in \code{classes} is \code{factor}.  Names of this list
are column names, and values are the query to perform to get the factor
levels for that column.  The query should return a distinct set of levels.
You don't have to specify \code{factorQueries}, but if you don't, \code{sqliteToRDS}
might take $N+1$ times as long to run as it would otherwise, where $N$ is
the number of factor columns.}
}
\value{
integer scalar; the number of result rows written to file \code{out}.
}
\description{
Export results of an sqlite query to an .rds file using limited
memory (Linux, OS X; not Windows)
}
\details{
Typically, exporting the contents of an sqlite database table as an
R .rds file has meant reading the entire table into R as a data.frame, then
using \code{saveRDS()}.  This requires memory proportional to the size of the
data.frame, but with a sufficiently large swap partition, this will still
work.  However, our experience on an Intel core-i7 server with 4 cores @
3.4 GHz, 32 G RAM, and a 256 SSD swap shows that our largest sites still
slow the server down to a grind when processing one site at a time.  To
permit this all to work on a lower spec server with multiple sites
potentially being processed at once, we need to do this with a much smaller
memory footprint, even at the expense of considerably longer running time.

This function serializes the results of an SQLite query as a data.frame
into an .rds file, using a fixed amount of memory that does not depend on
the size of the results.  Because sqlite stores data row-by-row, while .rds
files store them column by column, the main challenge is to transpose the
data without having it all in memory.  We do this with a single run of the
query, distributing columns to their own files, then concatenating and
compressing these into the final .rds file via a shell command.
}
\note{
End users should really be working with an on-disk .sqlite version of
their data, but we want to maintain some backward compatibility with users'
existing code.  Also, the details of the algorithm in this function depend
on the encoding inherent in the files serialize.c and Rinternals.h from the
R source tree.

The resulting .rds file uses bzip2 compression, which works with recent
versions of R, but might break \code{readRDS()} in older versions.

The algorithm, ignoring headers and footers, is:
\itemize{
\item for each column in the query result, open a temporary output file
\item while there are results remaining
\itemize{
\item fetch a block of query results
\item distribute data in the block among the column files
}
\item when all blocks have been distributed, close the temporary files and
concatenate them on disk into the target .rds file
}

The result is an .rds file in non-XDR little-endian format, which
should read more quickly into memory.

Data types are converted as so:
\itemize{
\item sqlite real: written as 8-byte doubles
\item sqlite int: written as 4-byte signed integers or logical (see below)
\item sqlite text: written as a factor
}

Additionally, \code{class()} attributes can be specified for any of the columns.
If "logical" or "integer" is specified for a column, it is written as a
native vector of that type.

If there are no result rows from the query, then the R value
\code{NULL} is saved to file \code{out}.

This function currently only works on linux (and OS X?)
because we use shell commands \code{cat} and \code{bzip2}.  The author
would appreciate information on how to implement this for
Windows platforms.
}
